{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982049d8",
   "metadata": {},
   "source": [
    "# Example of preprocessing pipeline \n",
    "\n",
    "### `Prerequisites:`\n",
    "\n",
    "1. #### Acquire data and manage them according to the [data management SOP]()\n",
    "\n",
    "2. #### In case you haven't installed `gks2p` package, install it from [here](https://github.com/gkeliris/gks2p_preprocess).\n",
    "\n",
    "3. #### Make sure you have prepared an `[Experiment].csv` file, see example [here](/home/georgioskeliris/GitHub/gks2p_preprocess/scripts/LRN2P_datasets.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61f9fd",
   "metadata": {},
   "source": [
    "### First, import the `gks2p` package functions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f640a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gks2p.datasets import *\n",
    "from gks2p.preprocess import *\n",
    "from gks2p.mkops import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3180eed",
   "metadata": {},
   "source": [
    "### Then, set the `basepath` and `fastbase` paths.\n",
    " **basepath** is the base location (usually on the NAS) where the processed data is stored (see [data management SOP]()).\n",
    "\n",
    " **fastbase** can be the same location or a local SSD for fast processing. This is where the binary suite2p files are stored. In our pipeline these binary files can be used again to import data for other analyses and thus they shouldn't be immediately deleted. Thus having that on the same location on the NAS is more convenient but could be a bit slower. Alternatively, an SSD can be used and they can be copied to the NAS later. However, in that case some other files may also need to be updated to have the correct paths to the binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ca86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/mnt/NAS_DataStorage/Data_active/LRN2P/'\n",
    "fastbase = '/mnt/NAS_DataStorage/Data_active/LRN2P/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f688e43",
   "metadata": {},
   "source": [
    "### The following python dictionary (`db`) is used to change some suite2p parameters from their default values\n",
    "\n",
    "*Note that first the default values are created and then the value pairs in db are overwriting those.*\n",
    "\n",
    "The `pipeline` parameter is used as a way to be able to run the analysis again with different parameters without overwriting the previous analysis (e.g. for comparisons). It defaults to the value `orig`. You can change it to some other name for a second analysis etc.\n",
    "\n",
    "The `tau` is the time-constant of the calcium sensitive dye (CSD) and used for the deconvolution. However, it seems to be also used for some smooting operations and in my experience the value of `1.5`, which is the time-constant of the slow variants of GCaMP6, seems to perform better for segmentation of some of our data - even if the fast GCaMP variant was used. This pipeline, allows to use this default value for the segmentation step, and then change it later to perform the deconvolution with the one appropriate with the correct tau of the used GCaMP variant.\n",
    "\n",
    "A `spatial scale` of 0, indicates to suite2p to try and automatically identify the spatial scale. This has to do with the size of the cells in pixels and it is usually around 6 (but it depends of course on the imaging resolution). If you know the value you want to use you can simply enter that instead of 0.\n",
    "\n",
    "The `reg_tif` argument indicates to suite2p whether to store the registered (motion corrected) tifs again. This is useful for exampel to be able to use these images in different softwhere. For the needs of our pipeline this is not necesssary because we have routines to directly import the binary data (note that the motion corrected binary are also stored by suite2p). Thus, to avoid over-duplication of the data we keep that to `False` unless needed for something else.\n",
    "\n",
    "For other parameters that can be added in the dictionary please check the [suite2p documentation](https://suite2p.readthedocs.io/en/latest/settings.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "156c2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {\n",
    "    'pipeline': 'orig',\n",
    "    'tau': 1.5,\n",
    "    'spatial_scale': 0,\n",
    "    'reg_tif': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb7e63",
   "metadata": {},
   "source": [
    "### Use the `datasetQuery` function to select datasets based on parameters such as *animal id*, *exp id*, *etc*.\n",
    "\n",
    "This will retrieve the matching dataset(s) from the [Experiment].csv files\n",
    "\n",
    "**MULTIDATA PROCESSING NOTE:**\n",
    "if **ds** has multiple datasets, the commands below will iterate and process all datasets one after another. However, for high memory consuming tasks, such as motion correction or segmentation it is probably best to not overload this with too many datasets at the same time. I noticed that such processes probably fail to clear their used resources completely, as the more you try to run the slower it gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f756bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = datasetQuery(cohort='lrn1', day='d0', experiment='DR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02353410",
   "metadata": {},
   "source": [
    "### Read the header information from the .tif files and create `ops files`\n",
    "\n",
    "`ops files` are files that can be used as input to suite2p and define different parameters of the data (such as sampling rate, number of planes etc.) plus the parameters that control the suite2p algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736277cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PROCESSING:\n",
      "datID                                                        1\n",
      "cohort                                                    lrn1\n",
      "day                                                         d0\n",
      "session                                                   ses1\n",
      "mouseID                                                   M827\n",
      "expID                                                       DR\n",
      "rawPath      /mnt/NAS_UserStorage/Mingyu/learning/2P imagin...\n",
      "firstTiff            M827_thy1_tg1_20250121_DR_00001_00001.tif\n",
      "matfolder    /mnt/NAS_UserStorage/Mingyu/Eyetracking/learni...\n",
      "matfile            M827_thy1tg1_DR_21_Jan_2025_15_35_45_01.mat\n",
      "eyefolder                                                  NaN\n",
      "eyefile                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "[579, 290, 0]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "gks2p_makeOps(ds, basepath, db=db, fastbase=fastbase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22595cf0",
   "metadata": {},
   "source": [
    "### Convert the .tif files to suite2p binary format and store\n",
    "\n",
    "The suite2p binaries are essentially matrices per scan ROI (thus notice that a multiplane scan will be converted to several files - a folder per plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fc50c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datID                                                        1\n",
      "cohort                                                    lrn1\n",
      "day                                                         d0\n",
      "session                                                   ses1\n",
      "mouseID                                                   M827\n",
      "expID                                                       DR\n",
      "rawPath      /mnt/NAS_UserStorage/Mingyu/learning/2P imagin...\n",
      "firstTiff            M827_thy1_tg1_20250121_DR_00001_00001.tif\n",
      "matfolder    /mnt/NAS_UserStorage/Mingyu/Eyetracking/learni...\n",
      "matfile            M827_thy1tg1_DR_21_Jan_2025_15_35_45_01.mat\n",
      "eyefolder                                                  NaN\n",
      "eyefile                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "{}\n",
      "NOTE: nplanes 1 nrois 3 => ops['nplanes'] = 3\n",
      "mesoscan\n",
      "** Found 21 tifs - converting to binary **\n",
      "6000 frames of binary, time 100.22 sec.\n",
      "12000 frames of binary, time 188.99 sec.\n",
      "time 200.71 sec. Wrote 12600 frames per binary for 3 planes\n"
     ]
    }
   ],
   "source": [
    "gks2p_toBinary(ds, basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7b6c6",
   "metadata": {},
   "source": [
    "### Motion correction (i.e. registration)\n",
    "\n",
    "Note that by default this will register all the planes of a particular dataset (when **iplaneList=None**). If sometimes the computer fails after a particular plane or for some reason you would like to (re)register particular planes the iplaneList argument can be used and given the specific planes (e.g. **iplaneList=[0 3 8]**)\n",
    "\n",
    "`Note:` *The motion corrected data are also stored as suite2p binary files in the same folder with the raw binary files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2268b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datID                                                        1\n",
      "cohort                                                    lrn1\n",
      "day                                                         d0\n",
      "session                                                   ses1\n",
      "mouseID                                                   M827\n",
      "expID                                                       DR\n",
      "rawPath      /mnt/NAS_UserStorage/Mingyu/learning/2P imagin...\n",
      "firstTiff            M827_thy1_tg1_20250121_DR_00001_00001.tif\n",
      "matfolder    /mnt/NAS_UserStorage/Mingyu/Eyetracking/learni...\n",
      "matfile            M827_thy1tg1_DR_21_Jan_2025_15_35_45_01.mat\n",
      "eyefolder                                                  NaN\n",
      "eyefile                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "REGISTERING: plane0\n",
      "Reference frame, 72.33 sec.\n",
      "Registered 500/12600 in 40.77s\n",
      "Registered 1000/12600 in 82.09s\n",
      "Registered 1500/12600 in 100.19s\n",
      "Registered 2000/12600 in 129.68s\n",
      "Registered 2500/12600 in 171.02s\n",
      "Registered 3000/12600 in 211.64s\n",
      "Registered 3500/12600 in 252.83s\n",
      "Registered 4000/12600 in 293.88s\n",
      "Registered 4500/12600 in 333.78s\n",
      "Registered 5000/12600 in 373.30s\n",
      "Registered 5500/12600 in 413.59s\n",
      "Registered 6000/12600 in 456.43s\n",
      "Registered 6500/12600 in 497.05s\n",
      "Registered 7000/12600 in 537.65s\n",
      "Registered 7500/12600 in 565.88s\n",
      "Registered 8000/12600 in 586.86s\n",
      "Registered 8500/12600 in 625.87s\n",
      "Registered 9000/12600 in 666.40s\n",
      "Registered 9500/12600 in 707.70s\n",
      "Registered 10000/12600 in 748.78s\n",
      "Registered 10500/12600 in 788.89s\n",
      "Registered 11000/12600 in 828.45s\n",
      "Registered 11500/12600 in 869.59s\n",
      "Registered 12000/12600 in 910.85s\n",
      "Registered 12500/12600 in 952.51s\n",
      "Registered 12600/12600 in 960.88s\n",
      "\n",
      "REGISTERING: plane1\n",
      "Reference frame, 31.64 sec.\n",
      "Registered 500/12600 in 52.45s\n",
      "Registered 1000/12600 in 130.75s\n",
      "Registered 1500/12600 in 208.93s\n",
      "Registered 2000/12600 in 285.47s\n",
      "Registered 2500/12600 in 360.51s\n",
      "Registered 3000/12600 in 442.34s\n",
      "Registered 3500/12600 in 526.80s\n",
      "Registered 4000/12600 in 605.19s\n",
      "Registered 4500/12600 in 681.31s\n",
      "Registered 5000/12600 in 759.11s\n",
      "Registered 5500/12600 in 820.58s\n",
      "Registered 6000/12600 in 900.31s\n",
      "Registered 6500/12600 in 977.81s\n",
      "Registered 7000/12600 in 1053.63s\n",
      "Registered 7500/12600 in 1130.33s\n",
      "Registered 8000/12600 in 1201.27s\n",
      "Registered 8500/12600 in 1277.95s\n",
      "Registered 9000/12600 in 1354.80s\n",
      "Registered 9500/12600 in 1436.48s\n",
      "Registered 10000/12600 in 1513.02s\n",
      "Registered 10500/12600 in 1586.91s\n",
      "Registered 11000/12600 in 1664.95s\n",
      "Registered 11500/12600 in 1741.27s\n",
      "Registered 12000/12600 in 1819.34s\n",
      "Registered 12500/12600 in 1894.21s\n",
      "Registered 12600/12600 in 1902.47s\n",
      "\n",
      "REGISTERING: plane2\n",
      "Reference frame, 74.01 sec.\n",
      "Registered 500/12600 in 42.09s\n",
      "Registered 1000/12600 in 83.13s\n",
      "Registered 1500/12600 in 124.12s\n",
      "Registered 2000/12600 in 166.06s\n",
      "Registered 2500/12600 in 209.31s\n",
      "Registered 3000/12600 in 251.14s\n",
      "Registered 3500/12600 in 293.16s\n",
      "Registered 4000/12600 in 335.38s\n",
      "Registered 4500/12600 in 370.13s\n",
      "Registered 5000/12600 in 401.03s\n",
      "Registered 5500/12600 in 441.50s\n",
      "Registered 6000/12600 in 483.87s\n",
      "Registered 6500/12600 in 525.84s\n",
      "Registered 7000/12600 in 567.71s\n",
      "Registered 7500/12600 in 609.71s\n",
      "Registered 8000/12600 in 651.56s\n",
      "Registered 8500/12600 in 692.86s\n",
      "Registered 9000/12600 in 733.92s\n",
      "Registered 9500/12600 in 776.66s\n",
      "Registered 10000/12600 in 817.79s\n",
      "Registered 10500/12600 in 846.70s\n",
      "Registered 11000/12600 in 876.78s\n",
      "Registered 11500/12600 in 917.75s\n",
      "Registered 12000/12600 in 959.36s\n",
      "Registered 12500/12600 in 1002.28s\n",
      "Registered 12600/12600 in 1010.56s\n"
     ]
    }
   ],
   "source": [
    "gks2p_register(ds, basepath, iplaneList=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88acb91b",
   "metadata": {},
   "source": [
    "### Segmentation of the images to ROIs (cells / non-cells)\n",
    "\n",
    "> This is the most critical step. One advantage of having the suite2p processes broken down to sub-modules is that one can repeat some critical steps with adjusted parameters until the result is satisfactory. If for example the result is problematic one can adjust some parameters in **db** and run again **gks2p_makeOps** before trying again **gks2p_segment**. Importantly, parameters are not important for **gks2p_toBinary** and usually also not important for **gks2p_register** (thus those two very time consuming steps can be skipped saving much time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a4719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datID                                                        1\n",
      "cohort                                                    lrn1\n",
      "day                                                         d0\n",
      "session                                                   ses1\n",
      "mouseID                                                   M827\n",
      "expID                                                       DR\n",
      "rawPath      /mnt/NAS_UserStorage/Mingyu/learning/2P imagin...\n",
      "firstTiff            M827_thy1_tg1_20250121_DR_00001_00001.tif\n",
      "matfolder    /mnt/NAS_UserStorage/Mingyu/Eyetracking/learni...\n",
      "matfile            M827_thy1tg1_DR_21_Jan_2025_15_35_45_01.mat\n",
      "eyefolder                                                  NaN\n",
      "eyefile                                                    NaN\n",
      "Name: 0, dtype: object\n",
      "\n",
      "SEGMENTING: plane0\n",
      "Binning movie in chunks of length 09\n",
      "Binned movie of size [1400,1302,294] created in 15.17 sec.\n",
      "NOTE: estimated spatial scale ~6 pixels, time epochs 1.17, threshold 5.83 \n",
      "0 ROIs, score=255.37\n",
      "1000 ROIs, score=46.92\n",
      "2000 ROIs, score=28.88\n",
      "3000 ROIs, score=20.34\n",
      "4000 ROIs, score=15.80\n",
      "Detected 5000 ROIs, 113.51 sec\n",
      "After removing overlaps, 4824 ROIs remain\n",
      "Masks created, 8.29 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georgioskeliris/GitHub/suite2p/suite2p/extraction/extract.py:125: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
      "  Fi[n] = np.dot(data[:, cell_ipix[n]], cell_lam[n])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fluorescence from 4824 ROIs in 12600 frames, 39.52 sec.\n",
      "['npix_norm', 'skew', 'compact']\n",
      "\n",
      "SEGMENTING: plane1\n",
      "Binning movie in chunks of length 09\n",
      "Binned movie of size [1400,1298,292] created in 15.11 sec.\n",
      "NOTE: estimated spatial scale ~6 pixels, time epochs 1.17, threshold 5.83 \n",
      "0 ROIs, score=184.16\n",
      "1000 ROIs, score=50.58\n",
      "2000 ROIs, score=32.51\n",
      "3000 ROIs, score=23.69\n",
      "4000 ROIs, score=18.12\n",
      "Detected 5000 ROIs, 127.06 sec\n",
      "After removing overlaps, 4866 ROIs remain\n",
      "Masks created, 8.25 sec.\n",
      "Extracted fluorescence from 4866 ROIs in 12600 frames, 34.14 sec.\n",
      "['npix_norm', 'skew', 'compact']\n",
      "\n",
      "SEGMENTING: plane2\n",
      "Binning movie in chunks of length 09\n",
      "Binned movie of size [1400,1296,288] created in 15.06 sec.\n",
      "NOTE: estimated spatial scale ~6 pixels, time epochs 1.17, threshold 5.83 \n",
      "0 ROIs, score=183.41\n",
      "1000 ROIs, score=43.21\n",
      "2000 ROIs, score=25.36\n",
      "3000 ROIs, score=16.91\n",
      "4000 ROIs, score=12.02\n",
      "Detected 5000 ROIs, 107.80 sec\n",
      "After removing overlaps, 4676 ROIs remain\n",
      "Masks created, 8.28 sec.\n",
      "Extracted fluorescence from 4676 ROIs in 12600 frames, 35.63 sec.\n",
      "['npix_norm', 'skew', 'compact']\n"
     ]
    }
   ],
   "source": [
    "gks2p_segment(ds, basepath, iplaneList=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad749a",
   "metadata": {},
   "source": [
    "### (Re)classigy cell / non-cells using another (onw-trained) classifier\n",
    "\n",
    "Sometimes the suite2p native classifer that classifies ROIs to cells and non-cells based on a selected probability doesn't perform optimally for different types of datasets. However, suite2p allows some manual correction of these categories (curation) and in addition allows a training of a classifier based on these curated data. Thus, if you have already curated multiple datasets and create a new classifier, there is a much better chance that this will perform better in newly acquired data of the same type and will thus not require too much effort for curation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5daf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gks2p_classify(ds, basepath, classfile=[paht_to_classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffad3ae",
   "metadata": {},
   "source": [
    "### Deconvolution using a different tau than segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e54b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gks2p_deconvolve(ds,basepath,0.7) # 0.7 here is the tau value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d090da",
   "metadata": {},
   "source": [
    "### Combine the single plane results to a single plane \n",
    "\n",
    "#### The `gks2p_combine(ds, basepath)` command combines the results from multiple planes or ROIs (Regions of Interest) after segmentation and processing steps.\n",
    "\n",
    "#### It aggregates the outputs (such as extracted signals, masks, and metadata) into unified files or structures for downstream analysis.\n",
    "\n",
    "#### This step is typically performed after motion correction and segmentation to facilitate further data analysis and visualization.\n",
    "\n",
    "`Note:` *This is mostly relevant for viewing all simultaneously in suite2p but in fact for other purposes like careful stitching and alignment, we use other procedures*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d96e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300 300 300]\n",
      "879.0\n",
      "1308.0\n",
      "[579 290   0]\n",
      "[0 0 0]\n",
      "appended plane 0 to combined view\n",
      "appended plane 1 to combined view\n",
      "appended plane 2 to combined view\n"
     ]
    }
   ],
   "source": [
    "gks2p_combine(ds, basepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03e90",
   "metadata": {},
   "source": [
    "## How to import in the pipeline datasets for which suite2p has already been runned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a12a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gks2p_import(dat, import_folder, basepath, fastbase=None, db={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973dbee",
   "metadata": {},
   "source": [
    "## Use `FISSA` to remove the effects of the neuropil and calculate DeltaF/F0\n",
    "\n",
    "#### `Prerequisites:`\n",
    "1. Install FISSA\n",
    "\n",
    "**Quick Guide:**\n",
    ">   pip install fissa\n",
    "\n",
    "For more info check this [link](https://github.com/rochefort-lab/fissa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d69ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that the gks2p package modules have already been imported, else we would need to import them here.\n",
    "\n",
    "# Here we import FISSA for further processing.\n",
    "import fissa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4318b",
   "metadata": {},
   "source": [
    "#### Process a dataset with `FISSA` to remove neuropil contamination from the cell ROIs and calculate the deltaF/F0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ced32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of interest using the datasetQuery function.\n",
    "ds = datasetQuery(cohort='lrn1', day='d6', mouseID='M827', experiment='FamNov2')\n",
    "\n",
    "gks2p_fissa(ds, basepath, iplaneList=None, nCores=None, use_reg_tif=False, redo_prep=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gks2p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
